{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PIL import Image, ImageEnhance\n","from skimage.draw import line\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sys\n","import cv2\n","import os\n","import pickle\n","from rembg.bg import remove as remove_background\n","import cairo"]},{"cell_type":"markdown","metadata":{},"source":["# Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Parameters \n","\n","# Program parameters\n","CLEAN_WORKSPACE = True # Clean all output files\n","\n","# I/O path parameters\n","INPUT_IMAGE_PATH = \"img/aldrin.png\"\n","OUTPUT_IMAGE_PATH = \"img_out/\" + os.path.splitext(INPUT_IMAGE_PATH[4:])[0]\n","\n","# Input image preprocessing parameters\n","CONTRAST_FACTOR = 2.0\n","INVERSE_INPUT_IMAGE = False\n","MASK_BACKGROUND_COLOR = 100 # 0-255, 0 means background is ignored, the closer to 255 the more important the background is\n","MASK_OBJECT_STRENGTH = 50 # 0-255, value added to edges of the mask to emphasize them and object itself\n","MASK_MAX_EDGES_STRENGTH = 255 # 0-255, maximum value of the mask edges\n","# Keep sum of MASK_OBJECT_STRENGTH and MASK_MAX_EDGES_STRENGTH to be less than 255 if you don't want to overpower the mask\n","\n","# Penalty calculation\n","# The algorithm is based on the following formula:\n","# penalty = (IC * sum(thread_pixels_in_input_image) + MC * sum(thread_pixels_in_mask)) / amount_of_thread_pixels + WC * thread_pixels_weighted_average\n","IC = 0.0 # input image coefficient\n","MC = 0.0 # mask image coefficient\n","WC = 1.0 # weighted average coefficient\n","DARKNESS = 170 # zobacz czy da sie to latwo zrobic \n","\n","# Visual parameters\n","NAIL_ARRANGEMENT = \"ellipse\" # Can be set to: \"ellipse\" / \"rectangle\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#\n","# Display \n","#\n","def display_image(image, rotate=False):\n","    if rotate:\n","        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    display(Image.fromarray(image))\n","\n","def display_mask(image, rotate=False):\n","    image = image.copy()\n","    if rotate:\n","        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    display(Image.fromarray(image))\n","\n","def display_nails(nails, image, rotate=False):\n","    canvas = np.ones(image.shape, np.uint8) * 255\n","    for nail in nails:\n","        canvas[nail[0], nail[1]] = 0\n","    display_image(canvas, rotate)\n","    return canvas\n","\n","def display_threads(threads, image, rotate=False):\n","    canvas = np.ones(image.shape, np.uint8) * 255\n","    for thread in threads:\n","        canvas = cv2.line(canvas, (thread[0][1], thread[0][0]), (thread[1][1], thread[1][0]), 0, 1)\n","    display_image(canvas, rotate)\n","    return canvas\n","\n","#\n","# Save\n","#\n","def save_threads(threads, image, rotate=False):\n","    canvas = np.ones(image.shape, np.uint8) * 255\n","    for thread in threads:\n","        canvas = cv2.line(canvas, (thread[0][1], thread[0][0]), (thread[1][1], thread[1][0]), 0, 1)\n","    if rotate:\n","        canvas = cv2.rotate(canvas, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    print(\"Trying to save image as: \" + OUTPUT_IMAGE_PATH[:7] + \"_png\" + OUTPUT_IMAGE_PATH[7:] + \"_\" + NAIL_ARRANGEMENT+ \"_\" + str(len(threads)) + \"_threaded.png\")\n","    cv2.imwrite(OUTPUT_IMAGE_PATH[:7] + \"_png\" + OUTPUT_IMAGE_PATH[7:] + \"_\" + NAIL_ARRANGEMENT + \"_\" + str(len(threads)) + \"_threaded.png\", canvas)\n","\n","def save_threads_svg(threads, size, rotate):\n","    print(\"Trying to save image as: \" + OUTPUT_IMAGE_PATH[:7] + \"_svg\" + OUTPUT_IMAGE_PATH[7:] + \"_\" + NAIL_ARRANGEMENT+ \"_\" + str(len(threads)) + \"_threaded.svg\")\n","    with cairo.SVGSurface(OUTPUT_IMAGE_PATH[:7] + \"_svg\" + OUTPUT_IMAGE_PATH[7:] + \"_\" + NAIL_ARRANGEMENT + \"_\" + str(len(threads)) + \"_threaded.svg\", size[1], size[0]) as surface:\n","        context = cairo.Context(surface)\n","        context.set_source_rgb(255, 255, 255)\n","        context.rectangle(0, 0, size[1]-1, size[0]-1)\n","        context.fill()\n","        context.set_source_rgb(0, 0, 0)\n","        for thread in threads:\n","            if rotate:\n","                thread = np.flip(thread, axis=1)\n","            context.move_to(thread[0][0], thread[0][1])\n","            for i in range(1, len(thread)):\n","                context.line_to(thread[i][0], thread[i][1])\n","            context.stroke()\n","\n","\n","def save_threads_path(threads):\n","    with open(OUTPUT_IMAGE_PATH[:7] + \"_txt\" + OUTPUT_IMAGE_PATH[7:] + \"_\" + NAIL_ARRANGEMENT + \"_\" + str(len(threads.split())-1) + \"_threaded_path.txt\", \"w\") as file:\n","        file.write(threads)\n","\n","def save_mask(image, rotate=False):\n","    print(\"Trying to save mask as: \" + OUTPUT_IMAGE_PATH[:7] + \"_png\" + OUTPUT_IMAGE_PATH[7:] + \"_mask.png\")\n","    canvas = image.copy()\n","    if rotate:\n","        canvas = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    cv2.imwrite(OUTPUT_IMAGE_PATH[:7] + \"_png\" + OUTPUT_IMAGE_PATH[7:] + \"_mask.png\", canvas)\n","\n","#\n","# Image\n","#\n","def decide_aspect_ratio(image):\n","    width, height = image.shape[1], image.shape[0]\n","    img_ar = width / height\n","    arr = np.asarray([1/1 , 3/4, 4/3, 4/5, 5/4])\n","    return arr[(np.abs(arr - img_ar)).argmin()]\n","    \n","def center_crop_to_aspect_ratio(image, aspect_ratio):\n","    width, height = image.shape[1], image.shape[0]\n","    img_ar = width / height\n","    if img_ar > aspect_ratio:\n","        return image[:, int((width - height * aspect_ratio) / 2):int((width + height * aspect_ratio) / 2)]\n","    else:\n","        return image[int((height - width / aspect_ratio) / 2):int((height + width / aspect_ratio) / 2), :]\n","\n","def resize_to_aspect_ratio(image, aspect_ratio):\n","    if aspect_ratio == 1/1:\n","        return cv2.resize(image, (1561, 1561))\n","    elif aspect_ratio == 3/4:\n","        return cv2.resize(image, (1321, 1761))\n","    elif aspect_ratio == 4/3:\n","        return cv2.resize(image, (1761, 1321))\n","    elif aspect_ratio == 4/5:\n","        return cv2.resize(image, (1441, 1801))\n","    elif aspect_ratio == 5/4:\n","        return cv2.resize(image, (1801, 1441))\n","\n","def get_input(): \n","    input_image = cv2.imread(INPUT_IMAGE_PATH, 0)\n","    if INVERSE_INPUT_IMAGE:\n","        input_image = cv2.bitwise_not(input_image)\n","\n","    aspect_ratio = decide_aspect_ratio(input_image)\n","    input_image = center_crop_to_aspect_ratio(input_image, aspect_ratio)\n","    input_image = resize_to_aspect_ratio(input_image, aspect_ratio)\n","\n","    # Background removal\n","    is_success, buffor_array = cv2.imencode(\".png\", input_image)\n","    byte_image = buffor_array.tobytes()\n","    output_buffor_array = remove_background(byte_image)\n","    image_no_bg_alpha = cv2.imdecode(np.frombuffer(output_buffor_array, np.uint8), cv2.IMREAD_UNCHANGED)\n","\n","    # Edge detection\n","    image_blur = cv2.GaussianBlur(input_image, (3, 3), 0)\n","    image_sobel_xy = cv2.convertScaleAbs(cv2.Sobel(src=image_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5))\n","    image_edges = np.interp(image_sobel_xy, (image_sobel_xy.min(), image_sobel_xy.max()), (0, MASK_MAX_EDGES_STRENGTH)).astype(np.uint8)\n","\n","    # Mask creation\n","    mask = image_edges.copy()\n","    for i in range(input_image.shape[0]):\n","        for j in range(input_image.shape[1]):\n","            if image_no_bg_alpha[i, j][3] == 0:\n","                mask[i, j] = MASK_BACKGROUND_COLOR\n","            else:\n","                mask[i, j] = MASK_BACKGROUND_COLOR + np.clip(mask[i, j] + MASK_OBJECT_STRENGTH, 0, 255)\n","    \n","    # Contrast enhancement\n","    mean = np.uint8(cv2.mean(input_image)[0])\n","    input_image = cv2.addWeighted(input_image, CONTRAST_FACTOR, np.ones_like(input_image) * mean, 1-CONTRAST_FACTOR, 0.0)\n","    return input_image, mask, aspect_ratio\n","\n","def get_new_image(dimensions):\n","    return np.ones(dimensions, np.uint8) * 255\n","\n","def draw_line(image, line, color):\n","    return cv2.line(image, (line[0][1], line[0][0]), (line[1][1], line[1][0]), color, 1)\n","\n","def draw_point(image, point, color):\n","    image[point[1], point[0]] = color\n","    return image\n","\n","#\n","# Points\n","#\n","def get_data_from_dictionaries(aspect_ratio, nail_arrangement):\n","    ar = \"\"\n","    rotate = False\n","    if aspect_ratio == 1/1:\n","        ar = \"1x1\"\n","    elif aspect_ratio == 3/4: \n","        ar = \"4x3\"\n","    elif aspect_ratio == 4/3:\n","        ar = \"4x3\"\n","        rotate = True\n","    elif aspect_ratio == 4/5:\n","        ar = \"5x4\"\n","    elif aspect_ratio == 5/4:\n","        ar = \"5x4\"\n","        rotate = True\n","\n","    with open(\"dictionaries/\" + nail_arrangement + \"_\" + ar + \".dat\", \"rb\") as dictionary_file:\n","        n, t, ntt, ttp = pickle.load(dictionary_file)\n","\n","    return n, t, ntt, ttp, rotate\n","    \n","def is_on_same_edge(point1, point2, dimensions):\n","    if point1[0] == 0 and point2[0] == 0:\n","        return True\n","    if point1[0] == dimensions[0] - 1 and point2[0] == dimensions[0] - 1:\n","        return True\n","    if point1[1] == 0 and point2[1] == 0:\n","        return True\n","    if point1[1] == dimensions[1] - 1 and point2[1] == dimensions[1] - 1:\n","        return True\n","    return False\n","\n","def get_other_end_of_thread(thread, nail):\n","    if np.array_equal(thread[0], nail):\n","        return thread[1]\n","    return thread[0]\n","\n","def get_nail_number(nail, n):\n","    for i in range(len(n)):\n","        if np.array_equal(nail, n[i]):\n","            return i\n","    return -1\n","\n","\n","#\n","# Test \n","#\n","# input_image = get_input_image()\n","\n","# input_image_edges = get_input_image_edges()\n","# output_image = get_new_image(input_image.shape)\n","\n","\n","\n","# print(\"Input image\")\n","# display_image(input_image)\n","\n","# print(\"Input image edges\")\n","# display_image(input_image_edges)\n","\n","# print(\"Output image\")\n","# display_image(output_image)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_thread_panelty(thread, ttp, input_image, input_image_mask):\n","    image_t_vals = input_image[tuple(ttp[thread.tobytes()].T)] # values of pixels in thread in input image\n","    mask_t_vals = input_image_mask[tuple(ttp[thread.tobytes()].T)] # values of pixels in thread in mask image\n","    # t_count = len(image_t_vals) # amount of pixels in thread (both in input image and mask image)\n","\n","    # penalty = (IC * np.sum(image_t_vals) + MC * np.sum(mask_t_vals)) / t_count + WC * np.average(image_t_vals, weights=mask_t_vals)\n","    \n","    return np.average(image_t_vals, weights=mask_t_vals)\n","\n","def get_best_fitting_thread(ntt, current_nail, ttp, input_image, input_image_edges): \n","    current_threads = ntt[current_nail.tobytes()]\n","    best_fitting_thread = current_threads[0]\n","    best_fitting_thread_penalty = 999999999\n","    for thread in current_threads:\n","        penalty = get_thread_panelty(thread, ttp, input_image, input_image_edges)\n","        if penalty < best_fitting_thread_penalty:\n","            best_fitting_thread = thread\n","            best_fitting_thread_penalty = penalty\n","    return best_fitting_thread, best_fitting_thread_penalty\n","\n","def produce_thread_art():\n","    if CLEAN_WORKSPACE:\n","        for filename in os.listdir(\"./img_out_txt\", \"./img_out_png\", \"./img_out_svg\"):\n","            if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\") or filename.endswith(\".svg\"):\n","                os.remove(os.path.join(\"./img_out_txt\", filename))\n","\n","    print(\"Producing \" + NAIL_ARRANGEMENT + \" thread art for: \", INPUT_IMAGE_PATH)\n","    \n","    input_image, input_image_mask, aspect_ratio = get_input()\n","    output_image = get_new_image(input_image.shape)\n","    thread_path = \"\"\n","\n","    print(\"Parameters:  \\tAspect Ratio: \" + str(aspect_ratio) + \n","                        \"\\t Mask BG: \" + str(MASK_BACKGROUND_COLOR) + \n","                        \"\\t Mask OBJ: \" + str(MASK_OBJECT_STRENGTH) + \n","                        \"\\t Mask EDGE: \" + str(MASK_MAX_EDGES_STRENGTH))\n","\n","    n, t, ntt, ttp, rotate = get_data_from_dictionaries(aspect_ratio, NAIL_ARRANGEMENT)\n","\n","    if rotate: # if dictionary exists for rotated image, use it\n","        input_image = cv2.rotate(input_image, cv2.ROTATE_90_CLOCKWISE)\n","        input_image_mask = cv2.rotate(input_image_mask, cv2.ROTATE_90_CLOCKWISE)\n","        output_image = cv2.rotate(output_image, cv2.ROTATE_90_CLOCKWISE)\n","\n","    used_threads = []\n","    current_nail = ntt[list(ntt)[0]][0][0] # start at more suitable one?\n","    thread_path = thread_path + str(get_nail_number(current_nail, n)) + \" \"\n","    current_input_image = input_image.copy()\n","\n","    print(\"Input image: \")\n","    display_image(current_input_image, rotate)\n","    \n","    print(\"Input image mask: \")\n","    display_mask(input_image_mask, rotate)\n","    save_mask(input_image_mask, rotate)\n","\n","    for i in range(1, 4001):\n","        current_threads = ntt[current_nail.tobytes()]\n","        if len(current_threads) == 0:\n","            print(\"No threads for nail\", current_nail)\n","            break # maybe figure out a way to continue by going back to previous nail and trying different thread\n","\n","        selected_thread, selected_thread_penalty = get_best_fitting_thread(ntt, current_nail, ttp, current_input_image, input_image_mask)\n","        next_nail = get_other_end_of_thread(selected_thread, current_nail)\n","        thread_path = thread_path + str(get_nail_number(next_nail, n)) + \" \"\n","\n","        used_threads.append(selected_thread)\n","\n","        ntt[current_nail.tobytes()] = np.array([a for a, skip in zip(ntt[current_nail.tobytes()], \n","                                        [np.allclose(a, selected_thread) for a in ntt[current_nail.tobytes()]]) if not skip])\n","        ntt[next_nail.tobytes()] = np.array([a for a, skip in zip(ntt[next_nail.tobytes()], \n","                                        [np.allclose(a, selected_thread) for a in ntt[next_nail.tobytes()]]) if not skip])\n","        \n","        # saves = [1000, 2000, 3000, 3500, 4000, 5000]\n","        saves = [1000, 1500, 2000, 2500, 3000, 3500]\n","        if i in saves:\n","            print(\"Current nail #\", i, \": \", str(current_nail))\n","            save_threads(used_threads, output_image, rotate)\n","            save_threads_svg(used_threads, output_image.shape, True)\n","            save_threads_path(thread_path)\n","            display_threads(used_threads, output_image, rotate)\n","\n","        draw_line(current_input_image, selected_thread, 255)\n","        current_nail = next_nail\n","\n","    return used_threads\n","    \n","    # return display_threads(used_threads, output_image, rotate)\n","\n","# # Run for all in DIR\n","# for filename in os.listdir(\"./img/test/\"):\n","#     if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n","#         INPUT_IMAGE_PATH = \"img/test/\" + filename\n","#         OUTPUT_IMAGE_PATH = \"img_out/\" + os.path.splitext(INPUT_IMAGE_PATH[4:])[0]\n","#         produce_thread_art()\n","\n","\n","# Run for one image specified in parameters\n","# threads_art = produce_thread_art()\n","\n","\n","MASK_BACKGROUND_COLOR = 50\n","MASK_OBJECT_STRENGTH = 100 \n","MASK_MAX_EDGES_STRENGTH = 255\n","threads_art = produce_thread_art()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":2}
